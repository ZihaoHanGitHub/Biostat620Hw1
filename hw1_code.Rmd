---
title: "Homework#1 Report Biostat620"
author: "Zihao Han"
date: "2024-02-04"
output: 
  pdf_document:
    latex_engine: pdflatex
    citation_package: natbib
header-includes:
  - \usepackage[numbers]{natbib}
  - \usepackage{graphicx} 
  - \usepackage[export]{adjustbox}
  - \usepackage{booktabs}
bibliography: ./biostat620hw1cite.bib

---
\textbf{GITHUB LINK:https://github.com/ZihaoHanGitHub/Biostat620Hw1}
```{r,warning=FALSE,include=FALSE}
# R setup and Load the data
library(lubridate)
library(scales)
library(gridExtra)
library(ggplot2)
library(dplyr)
library(GGally)
library(circular)
st = read.csv("./Biostat620ScreenTimeZihaoHan.csv")
head(st)
```

\section{PART1: DATA COLLECTION AND DATA PROCESSING}
\subsection{Problem 1:}
\subsubsection{(a)}
\textbf{Describe the purpose of the data collection, in which you state a scientic hypothesis of interest to justify your effort of data collection. Cite at least one reference to support your proposed hypothesis to be investigated. This hypothesis may be the one of a few possible hypotheses that you like to investigate in your rst group project with your teammates.}

This data collection we collect the total screen time, total social app used time, number of pickups, and the first pick up time, also the first pickup time could be considered as the sleep wake up time by adjusting the time zone of your mobile phone to avoid picking up your mobile phone in the early morning and interfering with the recording of sleep and wake time.

From these step, I'm interested in the scientific hypothesis that is the correlation between the total screen time and sleep wake up time (the first pickup times). In 2020, Pauliina Hiltunen et al. do the similar statistical inference among preschool children in Finland, they concluded that the used hours of smart phone and pad have a significant effect on the later bedtime, later wake-up time, less consistent sleep\cite{hiltunen2021relationship}. More than that, Alba do the similar research in 2018 among the adolescents (aged from 17 to 18), the higher tablet use found to be associated with reduced sleep efficiency and increased wake time after falling asleep \cite{cabre2019telecommunication}.

Therefore, depending on the purpose and description of data collection, and the previous scientific literature, the hypothesis, the correlation between the total screen time and sleep wake up time (the first pickup times), would be a reasonable and meaningful hypothesis for this project.

\subsubsection{(b)}
\textbf{Explain the role of Informed Consent Form in connection to the planned study and data collection}

With the rapid development of science and technology, data plays a vital role in many enterprises and research fields. In most cases, the personal information of participants can be clearly restored through data. This is unethical in data theory if the Informed Consent Form is not signed. In addition, the Informed Consent Form can give a clearer understanding of the purpose of the research. 

For example, this Informed Consent Form tells the participants what data will be collected, which researchers will have permission to use the data, and the signature must not The option to share with others protects the privacy of participants, ensures the rationality, security, and data ethics of this project, and reasonably protects the legitimate rights and interests of participants. For researchers, the Informed Consent Form can regulate researchers' obligations and responsibilities.

Overall, the Informed Consent Form is essential for a project that relies on data. It can protect the legitimate rights and interests of participants, standardize the obligations and responsibilities of researchers, and ensure the orderly and legal progress of the project.

\subsubsection{(c)}
\textbf{Describe the data collection plan, including when the data is collected, which types of variables in the data are collected, where the data is collected from, and how many data are collected before the data freeze. You may use tables to summarize your answers if necessary}

In this project, we would collect the total screen time, total social app used time, number of pickup times, and the first pickup times these four variables from the participants' phone, their data type is text, text, numeric, and date corresponding, moreover, it would be recommended to collect some useful basic demographic variables, for example, whether it is the weekday. 

In the example dataset provided by the instructor, we have to convert the screen time (text) and social app used time(text) to the number of minutes (numeric), it would be helpful when we do the modeling and analysis, the intuitive table is given by Table \ref{DesData}. 

As mentioned by the instructor of this course, the participants are recommended collect the data since the the phone stored (generally, the phone will retain data within 30 days) till the end of this project. However, in this assignments, we are aimed to collect the data from the stored till the Jan/26/2024.
\begin{table}[h]\label{DesData}
    \centering
    \begin{tabular}{lccccccc}
        \toprule
         Variable Name & Type & Counts &Freeze Date (hw1) & Freeze Date\\
        \midrule
        Total.ST & Text & 34& Jan/26/2024 & end of project\\
        Total.ST.min & Numeric & 34& Jan/26/2024& end of project\\
        Social.ST & Text& 34 & Jan/26/2024& end of project\\
        Social.ST.min & Numeric& 34 & Jan/26/2024& end of project\\
        Pickups & Numeric& 34 & Jan/26/2024& end of project\\
        Pickup.1st & Date& 34 & Jan/26/2024& end of project\\
        Demongraphic & Text/Boolean &  & Jan/26/2024& end of project\\
        \bottomrule
    \end{tabular}
    \caption{Example of the Data Type and Freezing date}
\end{table}

\subsubsection{(d)}
\textbf{Create and add two new variables into your dataset; they are, “daily proportion of social screen time” (defined as the ratio of daily total social screen time over daily total screen time) and “daily duration per use” (defined as the ratio of daily total screen time over daily total of pickups).}
```{r,echo=FALSE}
# First Convert the Screen Time and Social Screen Time to the minutes (numeric)
hm_to_min = function(text){
   split = strsplit(text,"h|m")
   hours = as.numeric(split[[1]][1])
   minutes = as.numeric(split[[1]][2])
   convert_minutes = hours * 60 + minutes
   return(convert_minutes)
}
st$Total.ST.min = sapply(st$Total.ST,hm_to_min)
st$Social.ST.min = sapply(st$Social.ST,hm_to_min)
head(st)
```
```{r,echo=FALSE}
# Compute these two adding variables
st$proportionOfSocial = st$Social.ST.min / st$Total.ST.min
st$duration = st$Total.ST.min / st$Pickups
head(st[c("Date","proportionOfSocial", "duration")])
```
\subsection{Problem 2}
\subsubsection{(a)}
\textbf{Make a time series plot of each of the five variables in your data. Describe temporal patterns from these time series plots.}
```{r,echo=FALSE}
# modify the date format fo dataset
st$Date <- as.Date(st$Date, format = "%m/%d/%y")
# Define a demographic variable indicate whether today I have course
st$CouseorNot <- ifelse(st$CourseToday >= 1, 1, 0)
st$CouseorNot <- as.factor(st$CouseorNot)
# Plot the Time Series of Total Screen Time
st.plot = ggplot(st, aes(x = Date, y = Total.ST.min, color = CouseorNot, group = 1)) +
  geom_line(color = "steelblue") +
  geom_point() +
  xlab("Date") +
  ylab("Total Screen Time in Minutes") +
  ylim((min(st$Total.ST.min) %/% 100 - 1) * 100, (max(st$Total.ST.min) %/% 100 + 1) * 100) +
  scale_color_manual(labels = c("No Course Today","Have Course Today"), 
                     values = c("black", "red")) +
  scale_x_date(labels = date_format("%m/%d")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 60, hjust = 1),
        legend.title = element_blank())
```
```{r,echo=FALSE}
social.plot = ggplot(st, aes(x = Date, y = Social.ST.min, color = CouseorNot, group = 1)) +
  geom_line(color = "steelblue") +
  geom_point() +
  xlab("Date") +
  ylab("Social APP Screen Time in Minutes") +
  ylim(max((min(st$Social.ST.min) %/% 100 - 1) * 100,0), (max(st$Social.ST.min) %/% 100 + 1) * 100) +
  scale_color_manual(labels = c("No Course Today","Have Course Today"), 
                     values = c("black", "red")) +
  scale_x_date(labels = date_format("%m/%d")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 60, hjust = 1),
        legend.title = element_blank())
grid.arrange(
  st.plot,
  social.plot,
  nrow = 2
)
```
```{r,echo=FALSE}
pickups.plot = ggplot(st, aes(x = Date, y = Pickups, color = CouseorNot, group = 1)) +
  geom_line(color = "steelblue") +
  geom_point() +
  xlab("Date") +
  ylab("Numbers of Pickups") +
  ylim(min(st$Pickups), max(st$Pickups)) +
  scale_color_manual(labels = c("No Course Today","Have Course Today"), 
                     values = c("black", "red")) +
  scale_x_date(labels = date_format("%m/%d")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 60, hjust = 1),
        legend.title = element_blank())

```
```{r,echo=FALSE}
proportion.plot = ggplot(st, aes(x = Date, y = proportionOfSocial, 
                                 color = CouseorNot, group = 1)) +
  geom_line(color = "steelblue") +
  geom_point() +
  xlab("Date") +
  ylab("Proportion of Social Screen Time") +
  ylim(0,max(st$proportionOfSocial)+0.1) +
  scale_color_manual(labels = c("No Course Today","Have Course Today"), 
                     values = c("black", "red")) +
  scale_x_date(labels = date_format("%m/%d")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 60, hjust = 1),
        legend.title = element_blank())

grid.arrange(
  pickups.plot,
  proportion.plot,
  nrow = 2
)
```
```{r,echo=FALSE}
duration.plot = ggplot(st, aes(x = Date, y = duration, 
                               color = CouseorNot, group = 1)) +
  geom_line(color = "steelblue") +
  geom_point() +
  xlab("Date") +
  ylab("Screen Time Duration per used") +
  ylim(max(min(st$duration)-5,0),max(st$duration)+5) +
  scale_color_manual(labels = c("No Course Today","Have Course Today"), 
                     values = c("black", "red")) +
  scale_x_date(labels = date_format("%m/%d")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 60, hjust = 1),
        legend.title = element_blank())
duration.plot
```
According to these five time series plot, I defined red point as the day I have course, and black points indicate that today I do not have course, usually the vocation or weekend, another additional information is my winter vocation is end at Jan 10, therefore, we could explore these temporal patterns. 

In total Screen Time plot (Figure 1), from Jan 10, the semester begin, the total screen time is started to be stable gradually, especially, the total screen time between whether I have course is significant different.

In the Social Screen Time plot (Figure 2), except the highest point (NOTE: that day I forget locked down my screen when I have a long-time phone call with my friend via Wechat, it causing my social time so long), the social screen time do not have intuitive trend shown in figure, but a step-conclusion is start from Jan 10, semester begin, the social screen time is significant different between course day and relax day, but it need more data to verify and support this step-conclusion.

In the number of pickups plot (Figure 3), it has a significant increasing trend by time, especially in the day I have course, combining with the plot of duration time per use (Figure 5), the the duration per pickups of course day is really shorter than the day I do not have course, more than that, it also has a significant decreasing trend than the day before the semester begin (Jan 10).

In the proportion of social app screen time plot (Figure 4), overall, it is stable. Except for 5 days among the 34 data points, it is higher than 0.4 and 4 days are lower than 0.2. The other data points are concentrated between 0.2 and 0.4. For the time being, no obvious demographic relationship has been found. information, this staged conclusion requires more data to support.

\subsubsection{(b)}
\textbf{Make pairwise scatterplots of five variables. Describe correlation patterns from these pairwise scatterplots. Which pair of variables among the five variables has the highest correlation?}
```{r,echo=FALSE}
# options(tcltk.qtk=FALSE)
corr.plot = ggpairs(st, columns = c("Total.ST.min", "Social.ST.min", "Pickups",
                                     "proportionOfSocial", "duration"),
                    columnLabels = c("Total ST", "Social ST", "Pickups",
                                     "Proportion of Social ST", "Duration")) +
  theme_bw()
corr.plot
```
From this pairwise correlation plot, we could find that there are five pair variables show a significant correlation, they are Social Screen Time vs. Total Screen Time ($corr = 0.617 ***$), Duration vs. Total Screen Time ($corr = 0.595 ***$), Proportion of Social Screen Time vs. Social Screen Time ($0.531 **$), Duration vs. Social Screen Time ($corr = 0.433 *$), Duration vs. Pickups ($corr = -0.773***$). 

To explain this, when I have more screen time leads to have a higher social screen time during the screen time significantly (Total Screen Time contain the social screen time), however we could find there is a nonsignificant and negative correlation between proportion of social ST vs. Total ST ($corr = -0.294$), meaning that, When my total screen time increases, although the social screen time increases, according to the correlation between proportion social ST and total ST, it is known that the social screen time does not increase proportionally, but increases compared to the original proportion. The value is smaller than the value corresponding to this ratio. More generally, as my overall screen time increases, I may be more inclined to use other apps (other than social apps).

For Duration vs. Total Screen Time ($corr = 0.595 ***$) Duration vs. Pickups ($corr = -0.773***$), it shows that there is a significant positive relationship between total ST and Duration per use, and a significant negative relationship between Duration per use and pickups. Since the correlation between pickups vs. total ST ($corr = -0.211$) is not significant, it could be assumed to be independent, therefore, when pickups times increase it would leads to a shorter duration adjusting for total ST; when the total ST increase, it would leads to a longer duration, adjusting for pickups.
\subsubsection{(c)}
\textbf{Make an occupation time curve for each of the five time series. Explain the pattern of individual curves.}
Since in the occupation time curve, the y-lab is shown by the $P(x>c)$, it could be rewrite as the $P(x>c)= 1-P(x\leq c)$, and we could using the R to compute the cumulative density function $F(c) = P(x\leq c)$, then to compute the ylab as $P(x>c)= 1-F(c)$.
```{r,echo=FALSE}
OCT = function(x,title){
  probabilities = ecdf(x)
  range = seq(0, max(x)*1.1, length.out = 100)
  cdf_plot <- probabilities(range)
  plot = ggplot() +
    geom_step(aes(x = range, y = 1- cdf_plot), color = "blue") +
    labs(title = title,
         x = "Magnitude c",
         y = "P(X>c)")
  return(plot)
}

grid.arrange(
  OCT(st$Total.ST.min, "Total Screen Time"),
  OCT(st$Social.ST.min, "Social Screen Time"),
  ncol = 2
)
grid.arrange(
  OCT(st$Pickups, "Pickups"),
  OCT(st$proportionOfSocial, "Proportion of Social ST"),
  ncol = 2
)
OCT(st$duration, "Duration")

```
From the Occupation-Time plot of these five variable generated by the cumulative density function (CDF),  we could see this curve decrese slowly at the edge of the range, and faster at the middle of these five variables. One has a extremly difference is the figure 2, at the magnitude $c = 200$, it has already near to the 0, it is the social screen time occupation time curve, so it mean that majority of the social ST is below the 200, there are few days social ST beyond the magnitude 200.


\subsubsection{(d)}
\textbf{Use the R function acf to display the serial dependence for each of the five time series. Are there any significant autocorrelations? Explain your results. Note that in this R function, you may set plot=FALSE to yield values of the autocorrelations.}

```{r,echo=FALSE}
par(mfrow = c(1, 2))
# Apply auto-correlation function (ACF)
acf(st$Total.ST.min)
acf(st$Social.ST.min)
acf(st$Pickups)
acf(st$proportionOfSocial)
acf(st$duration)
```
```{r,echo=FALSE}
# Using plot=FALSE to output the value
acf.st = acf(st$Total.ST.min,plot=FALSE)
acf.social = acf(st$Social.ST.min,plot=FALSE)
acf.pickups = acf(st$Pickups,plot=FALSE)
acf.prop = acf(st$proportionOfSocial,plot=FALSE)
acf.duration = acf(st$duration,plot=FALSE)
acf.st
acf.social
acf.pickups
acf.prop
acf.duration
```
From these five auto-correlation plot and the value computed by auto-correlation function (ACF), we could conclude that, these five variable (Total Screen Time, Social Screen Time, pickups, proportion of social Screen time, and duration) all shows nonsignificant autocorrelation over lags, since the vertical bars in the plot (except first 1, highest) all containing in the 95 \% confident interval which is showed in plot as two horizontal lines. Conclude that these five variables are recorded independents on the records of passed days.

\subsection{Problem 3}
\subsubsection{(a)}
\textbf{Transform (or covert) the time of first pickup to an angle ranged from 0 to 360 degree, treating midnight as 0 degree. For example, 6AM is 90 degree and noon is 180 degree.}
```{r,echo=FALSE}
Pickup1st_to_angle = function(text){
  split = strsplit(text,":")
  hours = as.numeric(split[[1]][1])
  minutes = as.numeric(split[[1]][2])
  convert_minutes = hours * 60 + minutes
  return(convert_minutes/1440*360)
}
st$Pickup.1st.angle = sapply(st$Pickup.1st,Pickup1st_to_angle)
head(st[c("Date","Pickup.1st.angle")])
```
\subsubsection{(b)}
\textbf{Make a scatterplot of the first pickup data on a 24-hour clock circle. Describe basic patterns from this scatterplot in terms of personal habit of first pickup.}
```{r,echo=FALSE}
pickups1st.cir = circular(st$Pickup.1st.angle,units = "degrees", template = "clock24")
plot(pickups1st.cir,col="blue")
```
From the basic scatter plot in a circle of clock 24 hours, we could find a simple distribution of first pick up times (could be considered as the wake up time), main distributed in 6:00 AM - 7:00 AM, and 10:00 AM to 1:30 PM, since we cannot see the histogram of this circle plot, according to the dataset recorded the data of during winter vocation and winter semester, the wake up time maybe could split by whether that day is the vocation. 
\subsubsection{(c)}
\textbf{Make a histogram plot on the circle in that you may choose a suitable bin size to create stacking. For example, you may set a bin size at 2.5 degree, which corresponds an interval of 10 minutes. Adjust the bin size to create different forms of histogram, and explain the reason that you choose a particular value to report your final histogram plot.}

```{r,echo=FALSE}
par(mfrow = c(1, 2))

# using bin = 10, corresponds to the interval of 40 mins
plot(pickups1st.cir, stack= TRUE, bins = 10, col = "blue")
title(main = "bin = 10")

# using bin = 30, corresponds to the interval of 120 mins
plot(pickups1st.cir, stack= TRUE, bins = 30, col = "blue")
title(main = "bin = 30")

# using bin = 60, corresponds to the interval of 240 mins
plot(pickups1st.cir, stack= TRUE, bins = 60, col = "blue")
title(main = "bin = 60")

# using bin = 90, corresponds to the interval of 360 mins
plot(pickups1st.cir, stack= TRUE, bins = 90, col = "blue")
title(main = "bin = 90")

par(mfrow = c(1, 1))
```

Finally, I choose the bin size of 60, corresponding to the time interval 240 mins, in this setting, Such a histogram is more intuitive and reduces information loss. For example, in images where the bin size is set to 10 and 30, many data points are all recorded in one column of the histogram, resulting in serious information loss; while setting the bin size to In the case of 90, the image becomes less intuitive. For example, at the time point of 10 o'clock, when the bin size is set to 60, it can be clearly seen that there are many data points that get up around 10 AM, and the bin size is This can be found less intuitively in 90 cases. So, in the end my bin size was set to 60.
\section{PART II: DATA ANALYSIS}
\subsection{Problem 4}
\subsubsection{(a)}
\textbf{Explain why the factor $S_t$ is needed in the Poisson distribution above.}

Since 
$$Y_t \sim \operatorname{Poisson}\left(S_t \lambda\right), t=1, \ldots, T$$
and $Y_t$ defined as the daily number of pickups at day t, $S_t$ defined as the total screen time, $\lambda$ defined as the hourly rate of pickups. We know that the mean of Poisson distribution is the $E[Y|S_t\lambda]=S_t\lambda$, all so in definition, $Y_t = S_t*\lambda_t$, $\lambda_t$ defined as the hourly rate of pickups at day t, the total screen time is important here to contribute the distribution fitness to the $Y_t$.
\subsubsection{(b)}
\textbf{Use the R function glm to estimate the rate parameter $\lambda$ in which ln(St) is included in the model as an offset.}

Since we estimate the parameter $\lambda$ and it is defined as the \textbf{hourly} rate pickups, therefore, we need to convert the $S_t$ from minutes to hourly.
```{r,echo=FALSE}
est.lambda = glm(Pickups ~ offset(log(Total.ST.min/60)),
            family = poisson,data = st)
summary(est.lambda)
```
Since we used the poisson regression model, and the link function is log-link function, the model could be described as:

$$
\ln (\text { Pickups })=2.32345+\ln (\text { Total.ST.min } / 60)
$$
the estimate of $\hat{\lambda}$ would be$\hat{\lambda} = exp(\frac{ln(Pickups)}{ln(Total.ST.min/60)})$

Therefore, the estimate of $\lambda$ is given by:
```{r,echo=FALSE}
cat("The estimate is",exp(coef(est.lambda)["(Intercept)"]),"\n")
```
\subsubsection{(c)}
\textbf{Define two dummy variables: $X_t = 1$ for day $t$ being a weekday and 0 for day $t$ being a weekend day; and $Z_t = 1$ for day t being January, 10 (the first day of the winter semester) or after, and 0 for day t before January, 10 (the winter holiday day).}

\textbf{Repeat part (b) for a model $ln(\lambda)=\beta_0+\beta_1*X_t+\beta_2*Z_t$, under which the rate parameter $\lambda$ differs between weekdays and weekends as well as between the winter semester and the winter holiday. This model is called log-linear model. Cleary, this rate parameter depends on day $t$. Use the R function glm to estimate the regression coefficients and answer the following questions.}

After create these two dummy variables, the summary of model generated by glm is given by:
```{r,echo=FALSE}
# define the dummy variable X_t
st$wday = wday(st$Date)
st$Xt = ifelse(st$wday >= 2 & st$wday <= 6, 1, 0)
# define the dummy variable Z_t
st$Zt = ifelse(st$Date>=as.Date("2024-01-10"),1,0)
# fit the model
est.lambda.dummy = glm(Pickups ~ Xt+Zt+
                         offset(log(Total.ST.min/60)),
                       family = poisson,
                       data=st)
summary(est.lambda.dummy)
```
\subsubsection{(c1)}
\textbf{Is there data evidence for significantly different behavior of daily pickups between weekdays and weekends? Justify your answer using the significance level $\alpha$ = 0.05.}

Since the P-value of regression coefficients of $X_t$ is $Pr(>|z|)=7.96e-07 < 0.05$, there is a significant correlation between the weekdays and weekends on number of daily pickups.

\subsubsection{(c2)}
\textbf{Is there data evidence for a significant change on the behavior of daily pickups after the winter semester began? Justify your answer using the significance level $\alpha$ = 0.05.}

Since the P-value of regression coefficients of $Z_t$ is $Pr(>|z|)< 2e-16< 0.05$, there is a significant correlation between the winter vocation and semester begin on number of daily pickups.

\subsection{Problem 5}
\subsubsection{(a)}
\textbf{Use the R function mle.vonmises from the R package circular to obtain the estimates of the two model parameters $\mu$ and $\lambda$ from your data of first pickups.}

Using the MLE vonmises to estimate the two parameter of $\mu$ and $\lambda$ needs to input a numerical value to compute, thus, the angle degree we calculated before would be suitable for this estimator.

```{r,warning=FALSE,echo=FALSE}
# apply the function mle.vonmises, and input the angle degree of first pickup times

est.mu.lambda = mle.vonmises(st$Pickup.1st.angle)
est.mu.lambda
```
Therefore, the estimate of $\hat{\mu}=2.786$ with standard error equal to 0.6064, the estimate of $\hat{\lambda} = 0.404$, with $se = 0.25$

\subsection{(b)}
\textbf{Based on the estimated parameters from part (a), use the R function pvonmises from the Rpackage circular to calculate the probability that your first pickup is 8:30AM or later.}

Since we use the function of pvonmises, it give us the probability of $P(X<a)$, and we need the probability of later than 8:30 AM, thus, we need one more step of calculating, $P(X>=a) = 1-P(X<a)$
```{r,echo=FALSE}
# convert the 8:30 AM to circular data
treshold = circular(2*pi*(8 + 30/60)/24)
probability = pvonmises(treshold,mu = est.mu.lambda$mu,
                        kappa = est.mu.lambda$kappa,
                        tol = 1e-4)
cat("The probability of first pickup time later than 8:30 AM with 1e-4 tolerence \n, and the parameters are estimated by (a), is",1- probability,"\n")
```

